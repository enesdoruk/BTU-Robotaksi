{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002091B77D1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8b84afce9b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblend_on_road\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import time\n",
    "\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "\n",
    "\n",
    "def road_lines(image):\n",
    "\n",
    "\n",
    "    small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    lane_image = imresize(lane_drawn, (416, 416, 3))\n",
    "\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "\n",
    "    cv2.imshow(\"image\", result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = load_model('full_CNN_model.h5')\n",
    "    lanes = Lanes()\n",
    "\n",
    "    btu = cv2.imread(\"btu.jpg\")\n",
    "    btu = cv2.resize(btu, dsize=(80,80))\n",
    "    carf = cv2.imread(\"carf.jpg\")\n",
    "    carf = cv2.resize(carf, dsize=(80,80))\n",
    "    \n",
    "    vid = cv2.VideoCapture(\"project_video.mp4\")\n",
    "\n",
    "    while (True):\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        if ret == True:\n",
    "\n",
    "            small_img = imresize(frame, (80, 160, 3))\n",
    "            scaled = cv2.resize(frame,(416,416))\n",
    "            small_img = np.array(small_img)\n",
    "            small_img = small_img[None, :, :, :]\n",
    "\n",
    "            prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "            lanes.recent_fit.append(prediction)\n",
    "            if len(lanes.recent_fit) > 5:\n",
    "                lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "            lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis=0)\n",
    "\n",
    "            blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "            lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "            lane_image = imresize(lane_drawn, (416, 416, 3))\n",
    "\n",
    "            result = cv2.addWeighted(scaled, 1, lane_image, 1, 0)\n",
    "            \n",
    "            mask = result.copy()\n",
    "            mask = cv2.rectangle(mask, pt1=(0, 0), pt2=(416, 100), color=(0, 0, 0), thickness=cv2.FILLED)\n",
    "            blend_on_road = cv2.addWeighted(src1=mask, alpha=0.2, src2=result, beta=0.8, gamma=0)\n",
    "            blend_on_road[5:85, 10:90, :] = btu\n",
    "            blend_on_road[5:85, 100:180, :] = carf\n",
    "\n",
    "            cv2.imshow(\"image\", blend_on_road)\n",
    "            \n",
    "            cv2.waitKey(0)\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
